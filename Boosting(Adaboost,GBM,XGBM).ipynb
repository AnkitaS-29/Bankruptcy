{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Both Train Data and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata      =  pd.read_csv(\"C:/Users/sirola/Downloads/CUTe/Traindata.csv\")\n",
    "validationdata =  pd.read_csv(\"C:/Users/sirola/Downloads/CUTe/Validationdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19684, 34)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8436, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Attr1', 'Attr3', 'Attr5', 'Attr6', 'Attr8', 'Attr13',\n",
       "       'Attr15', 'Attr19', 'Attr24', 'Attr25', 'Attr26', 'Attr27', 'Attr28',\n",
       "       'Attr29', 'Attr30', 'Attr36', 'Attr39', 'Attr40', 'Attr41', 'Attr42',\n",
       "       'Attr45', 'Attr46', 'Attr47', 'Attr48', 'Attr52', 'Attr53', 'Attr55',\n",
       "       'Attr57', 'Attr59', 'Attr60', 'Attr61', 'Attr63', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping the target variable\n",
    "x_train = traindata.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping the target variable\n",
    "x_test = validationdata.drop([\"target\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating another dataframe with target variable\n",
    "y_train = traindata['target']\n",
    "y_test = validationdata['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating adaboost-decision tree classifer object\n",
    "Adaboost_model = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators = 600,\n",
    "    learning_rate = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1, n_estimators=600, random_state=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model on the data\n",
    "%time Adaboost_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on Test \n",
    "y_preds = Adaboost_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Verify accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = Adaboost_model.predict(x_train)\n",
    "\n",
    "# Verify accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      4650\n",
      "          1       0.96      0.96      0.96      3786\n",
      "\n",
      "avg / total       0.96      0.96      0.96      8436\n",
      "\n",
      "[[4501  149]\n",
      " [ 147 3639]]\n",
      "Sensitivity :  0.9679569892473119\n",
      "Accuracy Rate: 0.9649122807017544\n",
      "Specificity :  0.9611727416798732\n"
     ]
    }
   ],
   "source": [
    "# Import classification report and confusion matrix to evaluate predictions\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Print out classification report \n",
    "print(classification_report(y_test,y_preds))\n",
    "# Print out confusion matrix\n",
    "cmat = confusion_matrix(y_test, y_preds)\n",
    "print(cmat)\n",
    "sensitivity1 = cmat[0,0]/(cmat[0,0]+cmat[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\n",
    "specificity1 = cmat[1,1]/(cmat[1,0]+cmat[1,1])\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     10972\n",
      "          1       1.00      1.00      1.00      8712\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19684\n",
      "\n",
      "[[10972     0]\n",
      " [    0  8712]]\n",
      "Sensitivity :  1.0\n",
      "Accuracy Rate: 1.0\n",
      "Specificity :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_train,y_pred))\n",
    "cmat1 = confusion_matrix(y_train,y_pred)\n",
    "print(cmat1)\n",
    "sensitivity2 = cmat1[0,0]/(cmat1[0,0]+cmat1[0,1])\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat1[0,0],cmat1[1,1]]),np.sum(cmat1))))\n",
    "specificity2 = cmat1[1,1]/(cmat1[1,0]+cmat1[1,1])\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search for getting better hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators' : [100, 150, 200],\n",
    "              'learning_rate' : [0.1, 0.5, 0.9]}\n",
    "\n",
    "Adaboost_model_clf = GridSearchCV(AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(max_depth=2)), param_grid, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'n_estimators': [100, 150, 200], 'learning_rate': [0.1, 0.5, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "%time Adaboost_model_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9451331030278398 {'learning_rate': 0.9, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_ada_model = Adaboost_model_clf.best_estimator_\n",
    "print (Adaboost_model_clf.best_score_, Adaboost_model_clf.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction on test set\n",
    "y_pred_test=best_ada_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9513987671882409\n"
     ]
    }
   ],
   "source": [
    "# Verify accuracy\n",
    "print(accuracy_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 17s\n",
      "Train Accuracy 0.9771895956106482\n",
      "Test Accuracy 0.9481981981981982\n"
     ]
    }
   ],
   "source": [
    "# Create adaboost-decision tree classifer object\n",
    "Adaboost_model = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators = 200,\n",
    "    learning_rate = 0.8\n",
    ")\n",
    "\n",
    "%time Adaboost_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on Test \n",
    "y_preds_train = Adaboost_model.predict(x_train)\n",
    "y_preds_test = Adaboost_model.predict(x_test)\n",
    "\n",
    "print(\"Train Accuracy\", accuracy_score(y_train, y_preds_train))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      4650\n",
      "          1       0.95      0.94      0.94      3786\n",
      "\n",
      "avg / total       0.95      0.95      0.95      8436\n",
      "\n",
      "[[4447  203]\n",
      " [ 234 3552]]\n",
      "Sensitivity :  0.9563440860215053\n",
      "Accuracy Rate: 0.9481981981981982\n",
      "Specificity :  0.9381933438985737\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_test,y_preds_test))\n",
    "#Print out confusion matrix\n",
    "cmat = confusion_matrix(y_test, y_preds_test)\n",
    "print(cmat)\n",
    "sensitivity1 = cmat[0,0]/(cmat[0,0]+cmat[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\n",
    "specificity1 = cmat[1,1]/(cmat[1,0]+cmat[1,1])\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     10972\n",
      "          1       0.98      0.97      0.97      8712\n",
      "\n",
      "avg / total       0.98      0.98      0.98     19684\n",
      "\n",
      "[[10772   200]\n",
      " [  249  8463]]\n",
      "Sensitivity :  0.98177178271965\n",
      "Accuracy Rate: 0.9771895956106482\n",
      "Specificity :  0.9714187327823691\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_train,y_preds_train))\n",
    "cmat1 = confusion_matrix(y_train,y_preds_train)\n",
    "print(cmat1)\n",
    "sensitivity2 = cmat1[0,0]/(cmat1[0,0]+cmat1[0,1])\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat1[0,0],cmat1[1,1]]),np.sum(cmat1))))\n",
    "specificity2 = cmat1[1,1]/(cmat1[1,0]+cmat1[1,1])\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model = GradientBoostingClassifier(n_estimators=50,\n",
    "                                       learning_rate=0.3,\n",
    "                                       subsample=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.3, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=0.8, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time GBM_model.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = GBM_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9186818397344713\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9304003251371672\n"
     ]
    }
   ],
   "source": [
    "y_preds = GBM_model.predict(x_train)\n",
    "\n",
    "# Verify accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93      4650\n",
      "          1       0.92      0.90      0.91      3786\n",
      "\n",
      "avg / total       0.92      0.92      0.92      8436\n",
      "\n",
      "[[4360  290]\n",
      " [ 396 3390]]\n",
      "Sensitivity :  0.9376344086021505\n",
      "Accuracy Rate: 0.9186818397344713\n",
      "Specificity :  0.8954041204437401\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_test,y_pred))\n",
    "# Print out confusion matrix\n",
    "cmat = confusion_matrix(y_test, y_pred)\n",
    "print(cmat)\n",
    "sensitivity1 = cmat[0,0]/(cmat[0,0]+cmat[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\n",
    "specificity1 = cmat[1,1]/(cmat[1,0]+cmat[1,1])\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94     10972\n",
      "          1       0.93      0.91      0.92      8712\n",
      "\n",
      "avg / total       0.93      0.93      0.93     19684\n",
      "\n",
      "[[10396   576]\n",
      " [  794  7918]]\n",
      "Sensitivity :  0.947502734232592\n",
      "Accuracy Rate: 0.9304003251371672\n",
      "Specificity :  0.9088613406795225\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_train,y_preds))\n",
    "cmat1 = confusion_matrix(y_train,y_preds)\n",
    "print(cmat1)\n",
    "sensitivity2 = cmat1[0,0]/(cmat1[0,0]+cmat1[0,1])\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat1[0,0],cmat1[1,1]]),np.sum(cmat1))))\n",
    "specificity2 = cmat1[1,1]/(cmat1[1,0]+cmat1[1,1])\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using Gridsearch for getting better hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\PYTHON\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "E:\\PYTHON\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Model in use\n",
    "GBM = GradientBoostingClassifier() \n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [100,150,200],\n",
    "           \"max_depth\" : [5, 10],\n",
    "           \"learning_rate\" : [0.1,0.5,0.9]}\n",
    " \n",
    "CV_GBM = GridSearchCV(estimator=GBM, param_grid=param_grid, cv= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in e:\\python\\lib\\site-packages (0.80)\n",
      "Requirement already satisfied: numpy in e:\\python\\lib\\site-packages (from xgboost) (1.14.3)\n",
      "Requirement already satisfied: scipy in e:\\python\\lib\\site-packages (from xgboost) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "XGB_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time XGB_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "print(XGB_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19684, 33)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = XGB_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9059981033665244\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9168868116236537\n"
     ]
    }
   ],
   "source": [
    "y_preds = XGB_model.predict(x_train)\n",
    "\n",
    "# Verify accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.92      4650\n",
      "          1       0.91      0.87      0.89      3786\n",
      "\n",
      "avg / total       0.91      0.91      0.91      8436\n",
      "\n",
      "[[4338  312]\n",
      " [ 481 3305]]\n",
      "Sensitivity :  0.9329032258064516\n",
      "Accuracy Rate: 0.9059981033665244\n",
      "Specificity :  0.8729529846804015\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_test,y_pred))\n",
    "# Print out confusion matrix\n",
    "cmat = confusion_matrix(y_test, y_pred)\n",
    "print(cmat)\n",
    "sensitivity1 = cmat[0,0]/(cmat[0,0]+cmat[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\n",
    "specificity1 = cmat[1,1]/(cmat[1,0]+cmat[1,1])\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.93     10972\n",
      "          1       0.92      0.89      0.90      8712\n",
      "\n",
      "avg / total       0.92      0.92      0.92     19684\n",
      "\n",
      "[[10331   641]\n",
      " [  995  7717]]\n",
      "Sensitivity :  0.9415785636164783\n",
      "Accuracy Rate: 0.9168868116236537\n",
      "Specificity :  0.8857897153351699\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_train,y_preds))\n",
    "cmat1 = confusion_matrix(y_train,y_preds)\n",
    "print(cmat1)\n",
    "sensitivity2 = cmat1[0,0]/(cmat1[0,0]+cmat1[0,1])\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat1[0,0],cmat1[1,1]]),np.sum(cmat1))))\n",
    "specificity2 = cmat1[1,1]/(cmat1[1,0]+cmat1[1,1])\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "XGB = XGBClassifier(n_jobs=-1)\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "param_grid = {\n",
    "     'colsample_bytree': np.linspace(0.5, 0.9, 2),\n",
    "     'n_estimators':[100, 200],\n",
    "     'max_depth': [10, 15, 20]\n",
    "}\n",
    "\n",
    " \n",
    "CV_XGB = GridSearchCV(estimator=XGB, param_grid=param_grid, cv= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the XGBOOST Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'colsample_bytree': array([0.5, 0.9]), 'n_estimators': [100, 200], 'max_depth': [10, 15, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time CV_XGB.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664194269457428 {'colsample_bytree': 0.5, 'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Find best model\n",
    "best_xgb_model = CV_XGB.best_estimator_\n",
    "print (CV_XGB.best_score_, CV_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=best_xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuaracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9706021811284969\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n",
      "Train Accuracy 1.0\n",
      "Test Accuracy 0.9706021811284969\n"
     ]
    }
   ],
   "source": [
    "# Create adaboost-decision tree classifer object\n",
    "XGB_model = XGBClassifier(colsample_bytree = 0.5,\n",
    "                          n_estimators=200,\n",
    "                          max_depth=10)\n",
    "\n",
    "%time XGB_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on Test \n",
    "y_preds_train = XGB_model.predict(x_train)\n",
    "y_preds_test = XGB_model.predict(x_test)\n",
    "\n",
    "print(\"Train Accuracy\", accuracy_score(y_train, y_preds_train))\n",
    "print(\"Test Accuracy\", accuracy_score(y_test, y_preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97      4650\n",
      "          1       0.97      0.96      0.97      3786\n",
      "\n",
      "avg / total       0.97      0.97      0.97      8436\n",
      "\n",
      "[[4535  115]\n",
      " [ 133 3653]]\n",
      "Sensitivity :  0.975268817204301\n",
      "Accuracy Rate: 0.9706021811284969\n",
      "Specificity :  0.9648705758055995\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_test,y_preds_test))\n",
    "#Print out confusion matrix\n",
    "cmat = confusion_matrix(y_test, y_preds_test)\n",
    "print(cmat)\n",
    "sensitivity1 = cmat[0,0]/(cmat[0,0]+cmat[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\n",
    "specificity1 = cmat[1,1]/(cmat[1,0]+cmat[1,1])\n",
    "print('Specificity : ', specificity1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     10972\n",
      "          1       1.00      1.00      1.00      8712\n",
      "\n",
      "avg / total       1.00      1.00      1.00     19684\n",
      "\n",
      "[[10972     0]\n",
      " [    0  8712]]\n",
      "Sensitivity :  1.0\n",
      "Accuracy Rate: 1.0\n",
      "Specificity :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Print out classification report \n",
    "print(classification_report(y_train,y_preds_train))\n",
    "cmat1 = confusion_matrix(y_train,y_preds_train)\n",
    "print(cmat1)\n",
    "sensitivity2 = cmat1[0,0]/(cmat1[0,0]+cmat1[0,1])\n",
    "print('Sensitivity : ', sensitivity2 )\n",
    "print('Accuracy Rate: {}'.format(np.divide(np.sum([cmat1[0,0],cmat1[1,1]]),np.sum(cmat1))))\n",
    "specificity2 = cmat1[1,1]/(cmat1[1,0]+cmat1[1,1])\n",
    "print('Specificity : ', specificity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
